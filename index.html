<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-Page Quiz App</title>
    <style>
        /* Your existing CSS remains unchanged */
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            margin: 0;
            padding: 20px;
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        .quiz-container {
            background: white;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
            padding: 30px;
            max-width: 900px;
            width: 100%;
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
        }
        .header h1 {
            color: #2c3e50;
            margin: 0;
            font-size: 2.5em;
        }
        #score {
            color: #3498db;
            font-size: 1.5em;
            font-weight: bold;
        }
        .question {
            background: #ecf0f1;
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 20px;
            transition: all 0.3s ease;
        }
        .question:hover {
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.05);
        }
        .question h3 {
            color: #2c3e50;
            margin: 0 0 15px 0;
            font-size: 1.2em;
        }
        .options {
            display: flex;
            flex-direction: column;
            gap: 10px;
        }
        .option {
            background: #f9f9f9;
            padding: 15px;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s ease;
            border: 2px solid #ddd;
        }
        .option:hover:not(.selected) {
            background: #e0e0e0;
            border-color: #3498db;
        }
        .option.selected.correct {
            background: #2ecc71;
            color: white;
            border-color: #27ae60;
        }
        .option.selected.incorrect {
            background: #e74c3c;
            color: white;
            border-color: #c0392b;
        }
        .navigation {
            display: flex;
            justify-content: space-between;
            margin-top: 30px;
        }
        .nav-btn {
            padding: 12px 25px;
            background: #3498db;
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-size: 1em;
            transition: background 0.3s ease;
        }
        .nav-btn:hover {
            background: #2980b9;
        }
        .nav-btn:disabled {
            background: #bdc3c7;
            cursor: not-allowed;
        }
        .shuffle-controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-bottom: 20px;
        }
        .shuffle-btn {
            padding: 10px 20px;
            background: #e67e22;
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-size: 1em;
            transition: background 0.3s ease;
        }
        .shuffle-btn:hover {
            background: #d35400;
        }
    </style>
</head>
<body>
    <div class="quiz-container">
        <div class="header">
            <h1>Quiz App</h1>
            <div id="score">Score: 0 / 0</div>
        </div>
        <div class="shuffle-controls">
            <button class="shuffle-btn" onclick="shuffleQuestions()">Shuffle Questions</button>
            <button class="shuffle-btn" onclick="noShuffle()">No Shuffle</button>
        </div>
        <div id="questions"></div>
        <div class="navigation">
            <button class="nav-btn" id="prevBtn" onclick="prevPage()">Previous</button>
            <button class="nav-btn" id="nextBtn" onclick="nextPage()">Next</button>
        </div>
    </div>

    <script>
        let questions = [
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the lecture on Text Retrieval and Information Extraction (Slides 20\u201323), which of the following statements about TF-IDF term weighting is correct?",
          "options": {
            "a": "TF-IDF combines term frequency (TF) with inverse document frequency (IDF) to reflect both local importance and global rarity of terms.",
            "b": "The IDF component increases for terms that appear in more documents, reducing their discriminative power.",
            "c": "TF-IDF weights are calculated by dividing the raw term frequency by the total number of terms in the document.",
            "d": "In the TF-IDF formula, N represents the average number of terms per document in the collection.",
            "e": "TF-IDF is primarily used in Boolean retrieval models to determine logical query matches."
          },
          "correct_answer": "a"
        },
        {
          "question": "According to GraphAnalysis.pdf (slides 30\u201332) and the associated lecture by Dr. Grant, which of the following is not an appropriate application of knowledge bases?",
          "options": {
            "a": "Storing unrelated, unstructured data for fast lookups",
            "b": "Improving what information a search engine can present",
            "c": "Supporting automatic Q&A systems",
            "d": "Providing situational awareness for current events, such as road closings",
            "e": "Allowing queries for domain-specific information, such as for legal or medical purposes"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the lecture by professors on Text Retrieval and Information Extraction, which step in the Information Extraction process is most crucial for distinguishing between identifying just individual entities (like 'Jeffrey Immelt' as a Person) and extracting a binary relationship involving those entities (like Person-Title: 'Jeffrey Immelt' - 'CEO')?",
          "options": {
            "a": "Association",
            "b": "Segmentation",
            "c": "Classification",
            "d": "Clustering",
            "e": "Normalization"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the Text Analysis Demo on codio, which of the following techniques is best suited for performing Named Entity Recognition (NER) on a multilingual dataset in the given demo?",
          "options": {
            "a": "Using SpaCy's xx_ent_wiki_sm pretrained model",
            "b": "Using sklearn's CountVectorizer with n-grams",
            "c": "Using KNN Classifier with cosine distance",
            "d": "Using SpaCy's en_core_web_sm model only",
            "e": "Using pandas read_json function with gzip compression"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to lecture Graph Analysis slide 18, How does a dead end differ from a spider trap in PageRank?",
          "options": {
            "a": "Dead ends have no outlinks, while spider traps have no outlinks to external pages.",
            "b": "Dead ends absorb all importance, while spider traps leak importance.",
            "c": "Dead ends violate column stochasticity, while spider traps preserve it.",
            "d": "Dead ends require teleports to fix, while spider traps are resolved by pruning.",
            "e": "Dead ends only occur in directed acyclic graphs, while spider traps require cycles."
          },
          "correct_answer": "a"
        },
        {
          "question": "Which of the following statements best describes the matrix formulation used in the PageRank algorithm?",
          "options": {
            "a": "Each element Mij\u200b represents a link from page i to page j, with rows summing to 1.",
            "b": "The matrix M is a symmetric matrix representing bidirectional web links.",
            "c": "The value Mij\u200b equals 1/dj\u200b if page j links to page i, where dj\u200b is the number of outlinks from j.",
            "d": "The PageRank vector is computed as r=MTr, where M is an upper triangular matrix.",
            "e": "Each column in matrix M sums to 0, ensuring convergence of the PageRank vector."
          },
          "correct_answer": "c"
        },
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the lecture on Text Retrieval and Information Extraction (Slides 20\u201323), which of the following statements about TF-IDF term weighting is correct?",
          "options": {
            "a": "TF-IDF combines term frequency (TF) with inverse document frequency (IDF) to reflect both local importance and global rarity of terms.",
            "b": "The IDF component increases for terms that appear in more documents, reducing their discriminative power.",
            "c": "TF-IDF weights are calculated by dividing the raw term frequency by the total number of terms in the document.",
            "d": "In the TF-IDF formula, N represents the average number of terms per document in the collection.",
            "e": "TF-IDF is primarily used in Boolean retrieval models to determine logical query matches."
          },
          "correct_answer": "a"
        },
        {
          "question": "According to GraphAnalysis.pdf (slides 30\u201332) and the associated lecture by Dr. Grant, which of the following is not an appropriate application of knowledge bases?",
          "options": {
            "a": "Storing unrelated, unstructured data for fast lookups",
            "b": "Improving what information a search engine can present",
            "c": "Supporting automatic Q&A systems",
            "d": "Providing situational awareness for current events, such as road closings",
            "e": "Allowing queries for domain-specific information, such as for legal or medical purposes"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the lecture by professors on Text Retrieval and Information Extraction, which step in the Information Extraction process is most crucial for distinguishing between identifying just individual entities (like 'Jeffrey Immelt' as a Person) and extracting a binary relationship involving those entities (like Person-Title: 'Jeffrey Immelt' - 'CEO')?",
          "options": {
            "a": "Association",
            "b": "Segmentation",
            "c": "Classification",
            "d": "Clustering",
            "e": "Normalization"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the Text Analysis Demo on codio, which of the following techniques is best suited for performing Named Entity Recognition (NER) on a multilingual dataset in the given demo?",
          "options": {
            "a": "Using SpaCy's xx_ent_wiki_sm pretrained model",
            "b": "Using sklearn's CountVectorizer with n-grams",
            "c": "Using KNN Classifier with cosine distance",
            "d": "Using SpaCy's en_core_web_sm model only",
            "e": "Using pandas read_json function with gzip compression"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to lecture Graph Analysis slide 18, How does a dead end differ from a spider trap in PageRank?",
          "options": {
            "a": "Dead ends have no outlinks, while spider traps have no outlinks to external pages.",
            "b": "Dead ends absorb all importance, while spider traps leak importance.",
            "c": "Dead ends violate column stochasticity, while spider traps preserve it.",
            "d": "Dead ends require teleports to fix, while spider traps are resolved by pruning.",
            "e": "Dead ends only occur in directed acyclic graphs, while spider traps require cycles."
          },
          "correct_answer": "a"
        },
        {
          "question": "Which of the following statements best describes the matrix formulation used in the PageRank algorithm?",
          "options": {
            "a": "Each element Mij\u200b represents a link from page i to page j, with rows summing to 1.",
            "b": "The matrix M is a symmetric matrix representing bidirectional web links.",
            "c": "The value Mij\u200b equals 1/dj\u200b if page j links to page i, where dj\u200b is the number of outlinks from j.",
            "d": "The PageRank vector is computed as r=MTr, where M is an upper triangular matrix.",
            "e": "Each column in matrix M sums to 0, ensuring convergence of the PageRank vector."
          },
          "correct_answer": "c"
        },
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the lecture on Text Retrieval and Information Extraction (Slides 20\u201323), which of the following statements about TF-IDF term weighting is correct?",
          "options": {
            "a": "TF-IDF combines term frequency (TF) with inverse document frequency (IDF) to reflect both local importance and global rarity of terms.",
            "b": "The IDF component increases for terms that appear in more documents, reducing their discriminative power.",
            "c": "TF-IDF weights are calculated by dividing the raw term frequency by the total number of terms in the document.",
            "d": "In the TF-IDF formula, N represents the average number of terms per document in the collection.",
            "e": "TF-IDF is primarily used in Boolean retrieval models to determine logical query matches."
          },
          "correct_answer": "a"
        },
        {
          "question": "According to GraphAnalysis.pdf (slides 30\u201332) and the associated lecture by Dr. Grant, which of the following is not an appropriate application of knowledge bases?",
          "options": {
            "a": "Storing unrelated, unstructured data for fast lookups",
            "b": "Improving what information a search engine can present",
            "c": "Supporting automatic Q&A systems",
            "d": "Providing situational awareness for current events, such as road closings",
            "e": "Allowing queries for domain-specific information, such as for legal or medical purposes"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the lecture by professors on Text Retrieval and Information Extraction, which step in the Information Extraction process is most crucial for distinguishing between identifying just individual entities (like 'Jeffrey Immelt' as a Person) and extracting a binary relationship involving those entities (like Person-Title: 'Jeffrey Immelt' - 'CEO')?",
          "options": {
            "a": "Association",
            "b": "Segmentation",
            "c": "Classification",
            "d": "Clustering",
            "e": "Normalization"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the Text Analysis Demo on codio, which of the following techniques is best suited for performing Named Entity Recognition (NER) on a multilingual dataset in the given demo?",
          "options": {
            "a": "Using SpaCy's xx_ent_wiki_sm pretrained model",
            "b": "Using sklearn's CountVectorizer with n-grams",
            "c": "Using KNN Classifier with cosine distance",
            "d": "Using SpaCy's en_core_web_sm model only",
            "e": "Using pandas read_json function with gzip compression"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to lecture Graph Analysis slide 18, How does a dead end differ from a spider trap in PageRank?",
          "options": {
            "a": "Dead ends have no outlinks, while spider traps have no outlinks to external pages.",
            "b": "Dead ends absorb all importance, while spider traps leak importance.",
            "c": "Dead ends violate column stochasticity, while spider traps preserve it.",
            "d": "Dead ends require teleports to fix, while spider traps are resolved by pruning.",
            "e": "Dead ends only occur in directed acyclic graphs, while spider traps require cycles."
          },
          "correct_answer": "a"
        },
        {
          "question": "Which of the following statements best describes the matrix formulation used in the PageRank algorithm?",
          "options": {
            "a": "Each element Mij\u200b represents a link from page i to page j, with rows summing to 1.",
            "b": "The matrix M is a symmetric matrix representing bidirectional web links.",
            "c": "The value Mij\u200b equals 1/dj\u200b if page j links to page i, where dj\u200b is the number of outlinks from j.",
            "d": "The PageRank vector is computed as r=MTr, where M is an upper triangular matrix.",
            "e": "Each column in matrix M sums to 0, ensuring convergence of the PageRank vector."
          },
          "correct_answer": "c"
        },
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the lecture on Text Retrieval and Information Extraction (Slides 20\u201323), which of the following statements about TF-IDF term weighting is correct?",
          "options": {
            "a": "TF-IDF combines term frequency (TF) with inverse document frequency (IDF) to reflect both local importance and global rarity of terms.",
            "b": "The IDF component increases for terms that appear in more documents, reducing their discriminative power.",
            "c": "TF-IDF weights are calculated by dividing the raw term frequency by the total number of terms in the document.",
            "d": "In the TF-IDF formula, N represents the average number of terms per document in the collection.",
            "e": "TF-IDF is primarily used in Boolean retrieval models to determine logical query matches."
          },
          "correct_answer": "a"
        },
        {
          "question": "According to GraphAnalysis.pdf (slides 30\u201332) and the associated lecture by Dr. Grant, which of the following is not an appropriate application of knowledge bases?",
          "options": {
            "a": "Storing unrelated, unstructured data for fast lookups",
            "b": "Improving what information a search engine can present",
            "c": "Supporting automatic Q&A systems",
            "d": "Providing situational awareness for current events, such as road closings",
            "e": "Allowing queries for domain-specific information, such as for legal or medical purposes"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the lecture by professors on Text Retrieval and Information Extraction, which step in the Information Extraction process is most crucial for distinguishing between identifying just individual entities (like 'Jeffrey Immelt' as a Person) and extracting a binary relationship involving those entities (like Person-Title: 'Jeffrey Immelt' - 'CEO')?",
          "options": {
            "a": "Association",
            "b": "Segmentation",
            "c": "Classification",
            "d": "Clustering",
            "e": "Normalization"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the Text Analysis Demo on codio, which of the following techniques is best suited for performing Named Entity Recognition (NER) on a multilingual dataset in the given demo?",
          "options": {
            "a": "Using SpaCy's xx_ent_wiki_sm pretrained model",
            "b": "Using sklearn's CountVectorizer with n-grams",
            "c": "Using KNN Classifier with cosine distance",
            "d": "Using SpaCy's en_core_web_sm model only",
            "e": "Using pandas read_json function with gzip compression"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to lecture Graph Analysis slide 18, How does a dead end differ from a spider trap in PageRank?",
          "options": {
            "a": "Dead ends have no outlinks, while spider traps have no outlinks to external pages.",
            "b": "Dead ends absorb all importance, while spider traps leak importance.",
            "c": "Dead ends violate column stochasticity, while spider traps preserve it.",
            "d": "Dead ends require teleports to fix, while spider traps are resolved by pruning.",
            "e": "Dead ends only occur in directed acyclic graphs, while spider traps require cycles."
          },
          "correct_answer": "a"
        },
        {
          "question": "Which of the following statements best describes the matrix formulation used in the PageRank algorithm?",
          "options": {
            "a": "Each element Mij\u200b represents a link from page i to page j, with rows summing to 1.",
            "b": "The matrix M is a symmetric matrix representing bidirectional web links.",
            "c": "The value Mij\u200b equals 1/dj\u200b if page j links to page i, where dj\u200b is the number of outlinks from j.",
            "d": "The PageRank vector is computed as r=MTr, where M is an upper triangular matrix.",
            "e": "Each column in matrix M sums to 0, ensuring convergence of the PageRank vector."
          },
          "correct_answer": "c"
        },
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the lecture on Text Retrieval and Information Extraction (Slides 20\u201323), which of the following statements about TF-IDF term weighting is correct?",
          "options": {
            "a": "TF-IDF combines term frequency (TF) with inverse document frequency (IDF) to reflect both local importance and global rarity of terms.",
            "b": "The IDF component increases for terms that appear in more documents, reducing their discriminative power.",
            "c": "TF-IDF weights are calculated by dividing the raw term frequency by the total number of terms in the document.",
            "d": "In the TF-IDF formula, N represents the average number of terms per document in the collection.",
            "e": "TF-IDF is primarily used in Boolean retrieval models to determine logical query matches."
          },
          "correct_answer": "a"
        },
        {
          "question": "According to GraphAnalysis.pdf (slides 30\u201332) and the associated lecture by Dr. Grant, which of the following is not an appropriate application of knowledge bases?",
          "options": {
            "a": "Storing unrelated, unstructured data for fast lookups",
            "b": "Improving what information a search engine can present",
            "c": "Supporting automatic Q&A systems",
            "d": "Providing situational awareness for current events, such as road closings",
            "e": "Allowing queries for domain-specific information, such as for legal or medical purposes"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the lecture by professors on Text Retrieval and Information Extraction, which step in the Information Extraction process is most crucial for distinguishing between identifying just individual entities (like 'Jeffrey Immelt' as a Person) and extracting a binary relationship involving those entities (like Person-Title: 'Jeffrey Immelt' - 'CEO')?",
          "options": {
            "a": "Association",
            "b": "Segmentation",
            "c": "Classification",
            "d": "Clustering",
            "e": "Normalization"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the Text Analysis Demo on codio, which of the following techniques is best suited for performing Named Entity Recognition (NER) on a multilingual dataset in the given demo?",
          "options": {
            "a": "Using SpaCy's xx_ent_wiki_sm pretrained model",
            "b": "Using sklearn's CountVectorizer with n-grams",
            "c": "Using KNN Classifier with cosine distance",
            "d": "Using SpaCy's en_core_web_sm model only",
            "e": "Using pandas read_json function with gzip compression"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to lecture Graph Analysis slide 18, How does a dead end differ from a spider trap in PageRank?",
          "options": {
            "a": "Dead ends have no outlinks, while spider traps have no outlinks to external pages.",
            "b": "Dead ends absorb all importance, while spider traps leak importance.",
            "c": "Dead ends violate column stochasticity, while spider traps preserve it.",
            "d": "Dead ends require teleports to fix, while spider traps are resolved by pruning.",
            "e": "Dead ends only occur in directed acyclic graphs, while spider traps require cycles."
          },
          "correct_answer": "a"
        },
        {
          "question": "Which of the following statements best describes the matrix formulation used in the PageRank algorithm?",
          "options": {
            "a": "Each element Mij\u200b represents a link from page i to page j, with rows summing to 1.",
            "b": "The matrix M is a symmetric matrix representing bidirectional web links.",
            "c": "The value Mij\u200b equals 1/dj\u200b if page j links to page i, where dj\u200b is the number of outlinks from j.",
            "d": "The PageRank vector is computed as r=MTr, where M is an upper triangular matrix.",
            "e": "Each column in matrix M sums to 0, ensuring convergence of the PageRank vector."
          },
          "correct_answer": "c"
        },
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the lecture on Text Retrieval and Information Extraction (Slides 20\u201323), which of the following statements about TF-IDF term weighting is correct?",
          "options": {
            "a": "TF-IDF combines term frequency (TF) with inverse document frequency (IDF) to reflect both local importance and global rarity of terms.",
            "b": "The IDF component increases for terms that appear in more documents, reducing their discriminative power.",
            "c": "TF-IDF weights are calculated by dividing the raw term frequency by the total number of terms in the document.",
            "d": "In the TF-IDF formula, N represents the average number of terms per document in the collection.",
            "e": "TF-IDF is primarily used in Boolean retrieval models to determine logical query matches."
          },
          "correct_answer": "a"
        },
        {
          "question": "According to GraphAnalysis.pdf (slides 30\u201332) and the associated lecture by Dr. Grant, which of the following is not an appropriate application of knowledge bases?",
          "options": {
            "a": "Storing unrelated, unstructured data for fast lookups",
            "b": "Improving what information a search engine can present",
            "c": "Supporting automatic Q&A systems",
            "d": "Providing situational awareness for current events, such as road closings",
            "e": "Allowing queries for domain-specific information, such as for legal or medical purposes"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the lecture by professors on Text Retrieval and Information Extraction, which step in the Information Extraction process is most crucial for distinguishing between identifying just individual entities (like 'Jeffrey Immelt' as a Person) and extracting a binary relationship involving those entities (like Person-Title: 'Jeffrey Immelt' - 'CEO')?",
          "options": {
            "a": "Association",
            "b": "Segmentation",
            "c": "Classification",
            "d": "Clustering",
            "e": "Normalization"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the Text Analysis Demo on codio, which of the following techniques is best suited for performing Named Entity Recognition (NER) on a multilingual dataset in the given demo?",
          "options": {
            "a": "Using SpaCy's xx_ent_wiki_sm pretrained model",
            "b": "Using sklearn's CountVectorizer with n-grams",
            "c": "Using KNN Classifier with cosine distance",
            "d": "Using SpaCy's en_core_web_sm model only",
            "e": "Using pandas read_json function with gzip compression"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to lecture Graph Analysis slide 18, How does a dead end differ from a spider trap in PageRank?",
          "options": {
            "a": "Dead ends have no outlinks, while spider traps have no outlinks to external pages.",
            "b": "Dead ends absorb all importance, while spider traps leak importance.",
            "c": "Dead ends violate column stochasticity, while spider traps preserve it.",
            "d": "Dead ends require teleports to fix, while spider traps are resolved by pruning.",
            "e": "Dead ends only occur in directed acyclic graphs, while spider traps require cycles."
          },
          "correct_answer": "a"
        },
        {
          "question": "Which of the following statements best describes the matrix formulation used in the PageRank algorithm?",
          "options": {
            "a": "Each element Mij\u200b represents a link from page i to page j, with rows summing to 1.",
            "b": "The matrix M is a symmetric matrix representing bidirectional web links.",
            "c": "The value Mij\u200b equals 1/dj\u200b if page j links to page i, where dj\u200b is the number of outlinks from j.",
            "d": "The PageRank vector is computed as r=MTr, where M is an upper triangular matrix.",
            "e": "Each column in matrix M sums to 0, ensuring convergence of the PageRank vector."
          },
          "correct_answer": "c"
        },
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the lecture on Text Retrieval and Information Extraction (Slides 20\u201323), which of the following statements about TF-IDF term weighting is correct?",
          "options": {
            "a": "TF-IDF combines term frequency (TF) with inverse document frequency (IDF) to reflect both local importance and global rarity of terms.",
            "b": "The IDF component increases for terms that appear in more documents, reducing their discriminative power.",
            "c": "TF-IDF weights are calculated by dividing the raw term frequency by the total number of terms in the document.",
            "d": "In the TF-IDF formula, N represents the average number of terms per document in the collection.",
            "e": "TF-IDF is primarily used in Boolean retrieval models to determine logical query matches."
          },
          "correct_answer": "a"
        },
        {
          "question": "According to GraphAnalysis.pdf (slides 30\u201332) and the associated lecture by Dr. Grant, which of the following is not an appropriate application of knowledge bases?",
          "options": {
            "a": "Storing unrelated, unstructured data for fast lookups",
            "b": "Improving what information a search engine can present",
            "c": "Supporting automatic Q&A systems",
            "d": "Providing situational awareness for current events, such as road closings",
            "e": "Allowing queries for domain-specific information, such as for legal or medical purposes"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the lecture by professors on Text Retrieval and Information Extraction, which step in the Information Extraction process is most crucial for distinguishing between identifying just individual entities (like 'Jeffrey Immelt' as a Person) and extracting a binary relationship involving those entities (like Person-Title: 'Jeffrey Immelt' - 'CEO')?",
          "options": {
            "a": "Association",
            "b": "Segmentation",
            "c": "Classification",
            "d": "Clustering",
            "e": "Normalization"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the Text Analysis Demo on codio, which of the following techniques is best suited for performing Named Entity Recognition (NER) on a multilingual dataset in the given demo?",
          "options": {
            "a": "Using SpaCy's xx_ent_wiki_sm pretrained model",
            "b": "Using sklearn's CountVectorizer with n-grams",
            "c": "Using KNN Classifier with cosine distance",
            "d": "Using SpaCy's en_core_web_sm model only",
            "e": "Using pandas read_json function with gzip compression"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to lecture Graph Analysis slide 18, How does a dead end differ from a spider trap in PageRank?",
          "options": {
            "a": "Dead ends have no outlinks, while spider traps have no outlinks to external pages.",
            "b": "Dead ends absorb all importance, while spider traps leak importance.",
            "c": "Dead ends violate column stochasticity, while spider traps preserve it.",
            "d": "Dead ends require teleports to fix, while spider traps are resolved by pruning.",
            "e": "Dead ends only occur in directed acyclic graphs, while spider traps require cycles."
          },
          "correct_answer": "a"
        },
        {
          "question": "Which of the following statements best describes the matrix formulation used in the PageRank algorithm?",
          "options": {
            "a": "Each element Mij\u200b represents a link from page i to page j, with rows summing to 1.",
            "b": "The matrix M is a symmetric matrix representing bidirectional web links.",
            "c": "The value Mij\u200b equals 1/dj\u200b if page j links to page i, where dj\u200b is the number of outlinks from j.",
            "d": "The PageRank vector is computed as r=MTr, where M is an upper triangular matrix.",
            "e": "Each column in matrix M sums to 0, ensuring convergence of the PageRank vector."
          },
          "correct_answer": "c"
        },
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the lecture on Text Retrieval and Information Extraction (Slides 20\u201323), which of the following statements about TF-IDF term weighting is correct?",
          "options": {
            "a": "TF-IDF combines term frequency (TF) with inverse document frequency (IDF) to reflect both local importance and global rarity of terms.",
            "b": "The IDF component increases for terms that appear in more documents, reducing their discriminative power.",
            "c": "TF-IDF weights are calculated by dividing the raw term frequency by the total number of terms in the document.",
            "d": "In the TF-IDF formula, N represents the average number of terms per document in the collection.",
            "e": "TF-IDF is primarily used in Boolean retrieval models to determine logical query matches."
          },
          "correct_answer": "a"
        },
        {
          "question": "According to GraphAnalysis.pdf (slides 30\u201332) and the associated lecture by Dr. Grant, which of the following is not an appropriate application of knowledge bases?",
          "options": {
            "a": "Storing unrelated, unstructured data for fast lookups",
            "b": "Improving what information a search engine can present",
            "c": "Supporting automatic Q&A systems",
            "d": "Providing situational awareness for current events, such as road closings",
            "e": "Allowing queries for domain-specific information, such as for legal or medical purposes"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the lecture by professors on Text Retrieval and Information Extraction, which step in the Information Extraction process is most crucial for distinguishing between identifying just individual entities (like 'Jeffrey Immelt' as a Person) and extracting a binary relationship involving those entities (like Person-Title: 'Jeffrey Immelt' - 'CEO')?",
          "options": {
            "a": "Association",
            "b": "Segmentation",
            "c": "Classification",
            "d": "Clustering",
            "e": "Normalization"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the Text Analysis Demo on codio, which of the following techniques is best suited for performing Named Entity Recognition (NER) on a multilingual dataset in the given demo?",
          "options": {
            "a": "Using SpaCy's xx_ent_wiki_sm pretrained model",
            "b": "Using sklearn's CountVectorizer with n-grams",
            "c": "Using KNN Classifier with cosine distance",
            "d": "Using SpaCy's en_core_web_sm model only",
            "e": "Using pandas read_json function with gzip compression"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to lecture Graph Analysis slide 18, How does a dead end differ from a spider trap in PageRank?",
          "options": {
            "a": "Dead ends have no outlinks, while spider traps have no outlinks to external pages.",
            "b": "Dead ends absorb all importance, while spider traps leak importance.",
            "c": "Dead ends violate column stochasticity, while spider traps preserve it.",
            "d": "Dead ends require teleports to fix, while spider traps are resolved by pruning.",
            "e": "Dead ends only occur in directed acyclic graphs, while spider traps require cycles."
          },
          "correct_answer": "a"
        },
        {
          "question": "Which of the following statements best describes the matrix formulation used in the PageRank algorithm?",
          "options": {
            "a": "Each element Mij\u200b represents a link from page i to page j, with rows summing to 1.",
            "b": "The matrix M is a symmetric matrix representing bidirectional web links.",
            "c": "The value Mij\u200b equals 1/dj\u200b if page j links to page i, where dj\u200b is the number of outlinks from j.",
            "d": "The PageRank vector is computed as r=MTr, where M is an upper triangular matrix.",
            "e": "Each column in matrix M sums to 0, ensuring convergence of the PageRank vector."
          },
          "correct_answer": "c"
        },
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the lecture on Text Retrieval and Information Extraction (Slides 20\u201323), which of the following statements about TF-IDF term weighting is correct?",
          "options": {
            "a": "TF-IDF combines term frequency (TF) with inverse document frequency (IDF) to reflect both local importance and global rarity of terms.",
            "b": "The IDF component increases for terms that appear in more documents, reducing their discriminative power.",
            "c": "TF-IDF weights are calculated by dividing the raw term frequency by the total number of terms in the document.",
            "d": "In the TF-IDF formula, N represents the average number of terms per document in the collection.",
            "e": "TF-IDF is primarily used in Boolean retrieval models to determine logical query matches."
          },
          "correct_answer": "a"
        },
        {
          "question": "According to GraphAnalysis.pdf (slides 30\u201332) and the associated lecture by Dr. Grant, which of the following is not an appropriate application of knowledge bases?",
          "options": {
            "a": "Storing unrelated, unstructured data for fast lookups",
            "b": "Improving what information a search engine can present",
            "c": "Supporting automatic Q&A systems",
            "d": "Providing situational awareness for current events, such as road closings",
            "e": "Allowing queries for domain-specific information, such as for legal or medical purposes"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the lecture by professors on Text Retrieval and Information Extraction, which step in the Information Extraction process is most crucial for distinguishing between identifying just individual entities (like 'Jeffrey Immelt' as a Person) and extracting a binary relationship involving those entities (like Person-Title: 'Jeffrey Immelt' - 'CEO')?",
          "options": {
            "a": "Association",
            "b": "Segmentation",
            "c": "Classification",
            "d": "Clustering",
            "e": "Normalization"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to the Text Analysis Demo on codio, which of the following techniques is best suited for performing Named Entity Recognition (NER) on a multilingual dataset in the given demo?",
          "options": {
            "a": "Using SpaCy's xx_ent_wiki_sm pretrained model",
            "b": "Using sklearn's CountVectorizer with n-grams",
            "c": "Using KNN Classifier with cosine distance",
            "d": "Using SpaCy's en_core_web_sm model only",
            "e": "Using pandas read_json function with gzip compression"
          },
          "correct_answer": "a"
        },
        {
          "question": "According to lecture Graph Analysis slide 18, How does a dead end differ from a spider trap in PageRank?",
          "options": {
            "a": "Dead ends have no outlinks, while spider traps have no outlinks to external pages.",
            "b": "Dead ends absorb all importance, while spider traps leak importance.",
            "c": "Dead ends violate column stochasticity, while spider traps preserve it.",
            "d": "Dead ends require teleports to fix, while spider traps are resolved by pruning.",
            "e": "Dead ends only occur in directed acyclic graphs, while spider traps require cycles."
          },
          "correct_answer": "a"
        },
        {
          "question": "Which of the following statements best describes the matrix formulation used in the PageRank algorithm?",
          "options": {
            "a": "Each element Mij\u200b represents a link from page i to page j, with rows summing to 1.",
            "b": "The matrix M is a symmetric matrix representing bidirectional web links.",
            "c": "The value Mij\u200b equals 1/dj\u200b if page j links to page i, where dj\u200b is the number of outlinks from j.",
            "d": "The PageRank vector is computed as r=MTr, where M is an upper triangular matrix.",
            "e": "Each column in matrix M sums to 0, ensuring convergence of the PageRank vector."
          },
          "correct_answer": "c"
        },
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the Graph Analysis lecture slides (CAP5771, Slide 35), why must the stochastic adjacency matrix M used in PageRank computation be modified when the web graph contains dead-end nodes (nodes with no outlinks)?",
          "options": {
            "a": "Because dead ends introduce columns of zeros in M, violating the column stochastic property required for computing a valid stationary distribution in PageRank.",
            "b": "Because dead ends cause the inlinking pages to accumulate infinite PageRank scores due to unbalanced link flow.",
            "c": "Because dead ends prevent the application of the random teleportation mechanism, forcing removal of such nodes before matrix computation.",
            "d": "Because dead ends disrupt the structure of the web graph, making the Markov chain irreducible and non-ergodic.",
            "e": "Because dead ends create rank sinks that intentionally attract high PageRank to improve web advertisement revenue."
          },
          "correct_answer": "a"
        },
        {
          "question": "In the TF-IDF weighting scheme, why is inverse document frequency (IDF) used?",
          "options": {
            "a": "To give higher importance to terms that appear in many documents.",
            "b": "To penalize terms that are too common across the document collection.",
            "c": "To count how frequently a term appears in a single document.",
            "d": "To normalize all term weights to a value between 0 and 1.",
            "e": "To increase the weight of stopwords during vector construction."
          },
          "correct_answer": "b"
        },
        {
          "question": "According to the lecture on Text Retrieval and Information Extraction (Slides 20\u201323), which of the following statements about TF-IDF term weighting is correct?",
          "options": {
            "a": "TF-IDF combines term frequency (TF) with inverse document frequency (IDF) to reflect both local importance and global rarity of terms.",
            "b": "The IDF component increases for terms that appear in more documents, reducing their discriminative power.",
            "c": "TF-IDF weights are calculated by dividing the raw term frequency by the total number of terms in the document.",
            "d": "In the TF-IDF formula, N represents the average number of terms per document in the collection.",
            "e": "TF-IDF is primarily used in Boolean retrieval models to determine logical query matches."
          },
          "correct_answer": "a"
        },
        {
          "question": "According to GraphAnalysis.pdf (slides 30\u201332) and the associated lecture by Dr. Grant, which of the following is not an appropriate application of knowledge bases?",
          "options": {
            "a": "Storing unrelated, unstructured data for fast lookups",
            "b": "Improving what information a search engine can present",
            "c": "Supporting automatic Q&A systems",
            "d": "Providing situational awareness for current events, such as road closings",
            "e": "Allowing queries for domain-specific information, such as for legal or medical purposes"
          },
          "correct_answer": "a"
        }
      ];
    
        let currentPage = 0;
        let score = 0;
        const questionsPerPage = 20;
        let totalPages = Math.ceil(questions.length / questionsPerPage);
        let answers = new Array(questions.length).fill(null);
        let shuffledOptions = [];
    
        function shuffle(array) {
            for (let i = array.length - 1; i > 0; i--) {
                const j = Math.floor(Math.random() * (i + 1));
                [array[i], array[j]] = [array[j], array[i]];
            }
            return array;
        }
    
        function shuffleQuestions() {
            shuffledOptions = shuffle([...questions]).map(q => ({
                ...q,
                options: shuffle(Object.entries(q.options).map(([key, value]) => ({ key, value })))
            }));
            answers = new Array(questions.length).fill(null);
            score = 0;
            currentPage = 0;
            loadPage();
        }
    
        function noShuffle() {
            shuffledOptions = questions.map(q => ({
                ...q,
                options: shuffle(Object.entries(q.options).map(([key, value]) => ({ key, value })))
            }));
            answers = new Array(questions.length).fill(null);
            score = 0;
            currentPage = 0;
            loadPage();
        }
    
        function loadPage() {
            const start = currentPage * questionsPerPage;
            const end = Math.min(start + questionsPerPage, questions.length);
            const pageQuestions = shuffledOptions.slice(start, end);
            const questionsDiv = document.getElementById('questions');
            questionsDiv.innerHTML = '';
    
            pageQuestions.forEach((q, index) => {
                const qIndex = start + index;
                const div = document.createElement('div');
                div.className = 'question';
                div.innerHTML = `<h3>${qIndex + 1}. ${q.question}</h3>`;
                const optionsDiv = document.createElement('div');
                optionsDiv.className = 'options';
    
                q.options.forEach(({ key, value }) => {
                    const optDiv = document.createElement('div');
                    optDiv.className = 'option';
                    optDiv.textContent = value;
    
                    if (answers[qIndex] !== null) {
                        if (key === q.correct_answer) {
                            optDiv.classList.add('selected', 'correct');
                        } else if (key === answers[qIndex]) {
                            optDiv.classList.add('selected', 'incorrect');
                        }
                        optDiv.style.cursor = 'default';
                    } else {
                        optDiv.onclick = () => selectAnswer(qIndex, key, q.correct_answer);
                    }
    
                    optionsDiv.appendChild(optDiv);
                });
    
                div.appendChild(optionsDiv);
                questionsDiv.appendChild(div);
            });
    
            document.getElementById('prevBtn').disabled = currentPage === 0;
            document.getElementById('nextBtn').textContent = currentPage === totalPages - 1 ? 'Finish' : 'Next';
            document.getElementById('score').textContent = `Score: ${score} / ${questions.length}`;
        }
    
        function selectAnswer(qIndex, selectedKey, correctKey) {
            if (answers[qIndex] !== null) return;
            answers[qIndex] = selectedKey;
            if (selectedKey === correctKey) score++;
            loadPage();
        }
    
        function nextPage() {
            if (currentPage < totalPages - 1) {
                currentPage++;
                loadPage();
            } else {
                alert(`Quiz Completed! Final Score: ${score} / ${questions.length}`);
            }
        }
    
        function prevPage() {
            if (currentPage > 0) {
                currentPage--;
                loadPage();
            }
        }
    
        window.onload = () => {
            noShuffle(); // or shuffleQuestions() if you want default random
        };
    </script>
    
</body>
</html>
